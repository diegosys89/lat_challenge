{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de base de datos con pandas\n",
    "\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene\n",
    "por cada uno de esos días. Debe incluir las siguientes funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting q1_time.py\n"
     ]
    }
   ],
   "source": [
    "%%file q1_time.py\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    tweets_data = pd.read_json(file_path, lines = \"records\")\n",
    "\n",
    "    #Get top 10 dates\n",
    "    tweets_data = tweets_data[[\"date\",\"user\",\"id\"]]\n",
    "    tweets_data[\"date\"] = tweets_data[\"date\"].dt.date\n",
    "    tweets_data[\"user\"] = tweets_data[\"user\"].str.get(\"username\")\n",
    "    tweets_data.head()\n",
    "\n",
    "    #top 10 days\n",
    "    top_10_days = tweets_data.groupby([\"date\"]).count()\n",
    "    top_10_days = top_10_days.sort_values(\"id\", ascending=False).head(10)\n",
    "    top_10_days = list(top_10_days.index)\n",
    "    \n",
    "    #filter data and group by date and user\n",
    "    tweets_data = tweets_data.loc[tweets_data[\"date\"].isin(top_10_days)]\n",
    "    tweets_data = tweets_data.groupby([\"date\",\"user\"]).count()\n",
    "\n",
    "    tweets_data = tweets_data.sort_values([\"date\",\"id\"], ascending=False)\n",
    "    tweets_data = tweets_data.reset_index().groupby(\"date\").first()\n",
    "    \n",
    "    tweets_data = [tuple(i) for i in tweets_data[[\"user\"]].itertuples()]\n",
    "    return tweets_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/diego/Documents/TestChallenges/Option/test20230924/q1_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     5   1980.1 MiB   1980.1 MiB           1   def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "     6   2046.9 MiB     66.8 MiB           1       tweets_data = pd.read_json(file_path, lines = \"records\")\n",
      "     7                                         \n",
      "     8                                             #Get top 10 dates\n",
      "     9   2046.9 MiB      0.0 MiB           1       tweets_data = tweets_data[[\"date\",\"user\",\"id\"]]\n",
      "    10   2046.9 MiB      0.0 MiB           1       tweets_data[\"date\"] = tweets_data[\"date\"].dt.date\n",
      "    11   2046.9 MiB      0.0 MiB           1       tweets_data[\"user\"] = tweets_data[\"user\"].str.get(\"username\")\n",
      "    12   2046.9 MiB      0.0 MiB           1       tweets_data.head()\n",
      "    13                                         \n",
      "    14                                             #top 10 days\n",
      "    15   2046.9 MiB      0.0 MiB           1       top_10_days = tweets_data.groupby([\"date\"]).count()\n",
      "    16   2046.9 MiB      0.0 MiB           1       top_10_days = top_10_days.sort_values(\"id\", ascending=False).head(10)\n",
      "    17   2046.9 MiB      0.0 MiB           1       top_10_days = list(top_10_days.index)\n",
      "    18                                             \n",
      "    19                                             #filter data and group by date and user\n",
      "    20   2046.9 MiB      0.0 MiB           1       tweets_data = tweets_data.loc[tweets_data[\"date\"].isin(top_10_days)]\n",
      "    21   2046.9 MiB      0.0 MiB           1       tweets_data = tweets_data.groupby([\"date\",\"user\"]).count()\n",
      "    22                                         \n",
      "    23   2046.9 MiB      0.0 MiB           1       tweets_data = tweets_data.sort_values([\"date\",\"id\"], ascending=False)\n",
      "    24   2046.9 MiB      0.0 MiB           1       tweets_data = tweets_data.reset_index().groupby(\"date\").first()\n",
      "    25                                             \n",
      "    26   2046.9 MiB      0.0 MiB          13       tweets_data = [tuple(i) for i in tweets_data[[\"user\"]].itertuples()]\n",
      "    27   2046.9 MiB      0.0 MiB           1       return tweets_data"
     ]
    }
   ],
   "source": [
    "from q1_time import q1_time\n",
    "%mprun -f q1_time q1_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 23.3838 s\n",
      "File: /home/diego/Documents/TestChallenges/Option/test20230924/q1_time.py\n",
      "Function: q1_time at line 5\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     5                                           def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "     6         1        2e+10    2e+10     92.1      tweets_data = pd.read_json(file_path, lines = \"records\")\n",
      "     7                                           \n",
      "     8                                               #Get top 10 dates\n",
      "     9         1  891351696.0    9e+08      3.8      tweets_data = tweets_data[[\"date\",\"user\",\"id\"]]\n",
      "    10         1  121636440.0    1e+08      0.5      tweets_data[\"date\"] = tweets_data[\"date\"].dt.date\n",
      "    11         1  360346964.0    4e+08      1.5      tweets_data[\"user\"] = tweets_data[\"user\"].str.get(\"username\")\n",
      "    12         1     561518.0 561518.0      0.0      tweets_data.head()\n",
      "    13                                           \n",
      "    14                                               #top 10 days\n",
      "    15         1   93783169.0    9e+07      0.4      top_10_days = tweets_data.groupby([\"date\"]).count()\n",
      "    16         1    1513882.0    2e+06      0.0      top_10_days = top_10_days.sort_values(\"id\", ascending=False).head(10)\n",
      "    17         1      26291.0  26291.0      0.0      top_10_days = list(top_10_days.index)\n",
      "    18                                               \n",
      "    19                                               #filter data and group by date and user\n",
      "    20         1   66745507.0    7e+07      0.3      tweets_data = tweets_data.loc[tweets_data[\"date\"].isin(top_10_days)]\n",
      "    21         1  240350698.0    2e+08      1.0      tweets_data = tweets_data.groupby([\"date\",\"user\"]).count()\n",
      "    22                                           \n",
      "    23         1   22046975.0    2e+07      0.1      tweets_data = tweets_data.sort_values([\"date\",\"id\"], ascending=False)\n",
      "    24         1   38321801.0    4e+07      0.2      tweets_data = tweets_data.reset_index().groupby(\"date\").first()\n",
      "    25                                               \n",
      "    26         1    2654797.0    3e+06      0.0      tweets_data = [tuple(i) for i in tweets_data[[\"user\"]].itertuples()]\n",
      "    27         1        809.0    809.0      0.0      return tweets_data"
     ]
    }
   ],
   "source": [
    "%lprun -f q1_time q1_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Los top 10 emojis más usados con su respectivo conteo. Debe incluir las siguientes funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@)\n",
    "que registra cada uno de ellos. Debe incluir las siguientes funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    return 0"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "445f001600bf7eb0ddc22245e91c6123825f79238ec2a014331a6132a9c2d200"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
