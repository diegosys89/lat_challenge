{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de base de datos con pandas\n",
    "\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la primera version se puede notar claramente que el cuello de botella corresponde a la lectura y parseo del archivo Json, en donde incluso se observa que el alrededor del 92% del tiempo de uso llega a ser por el tiempo de lectura del archivo json\n",
    "\n",
    "Para la lectura del archivo Json se creará en este caso una función que optimice el tiempo de lectura del archivo json y retornado solo los campos deseados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene\n",
    "por cada uno de esos días. Debe incluir las siguientes funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    # Lectura del archivo y obteniendo los datos que necesitamos\n",
    "    file1 = open(file_path, 'r')\n",
    "    Lines = file1.readlines()\n",
    "    data = []\n",
    "\n",
    "    for line in Lines:\n",
    "        json_value = json.loads(line)\n",
    "        user = json_value.get(\"user\").get(\"username\")\n",
    "        date = datetime.strptime(json_value.get(\"date\")[:10], \"%Y-%m-%d\").date()\n",
    "        data_id = json_value.get(\"id\")\n",
    "        data.append({\"date\":date, \"user\":user, \"id\":data_id})\n",
    "    \n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    #top 10 days\n",
    "    top_10_days = tweets_data.groupby([\"date\"]).count()\n",
    "    top_10_days = top_10_days.sort_values(\"id\", ascending=False).head(10)\n",
    "    top_10_days = list(top_10_days.index)\n",
    "    \n",
    "    #filter data and group by date and user\n",
    "    tweets_data = tweets_data.loc[tweets_data[\"date\"].isin(top_10_days)]\n",
    "    tweets_data = tweets_data.groupby([\"date\",\"user\"]).count()\n",
    "\n",
    "    tweets_data = tweets_data.sort_values([\"date\",\"id\"], ascending=False)\n",
    "    tweets_data = tweets_data.reset_index().groupby(\"date\").first()\n",
    "    \n",
    "    tweets_data = [tuple(i) for i in tweets_data[[\"user\"]].itertuples()]\n",
    "    return tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3 s ± 1.27 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en este caso el valor de lectura de tiempo se reduce considerablemente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de optimizacion de memoria utilizaremos archivos en disco que almacenen datos de manera temporal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dividirá la lectura en varios lotes, aplicando una tecnica de map reduce y guardando los archivos con los resultados previos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_memory(file_path):\n",
    "    # Create dict of date values and num of lines in file\n",
    "    file_lines = {}\n",
    "\n",
    "    # Open the file for reading\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            json_value = json.loads(line)\n",
    "            date = json_value.get(\"date\")[:10]\n",
    "            user = json_value.get(\"user\").get(\"username\")\n",
    "            data_id = json_value.get(\"id\")\n",
    "            data = {\"user\":user, \"id\":data_id}\n",
    "            with open(f\"data_q1/{date}\",\"a\") as fwrite:\n",
    "                fwrite.write(json.dumps(data)+\"\\n\")\n",
    "                try:\n",
    "                    file_lines[date] += 1 \n",
    "                except:\n",
    "                    file_lines[date] = 0\n",
    "    \n",
    "    top_10_days = pd.DataFrame([{\"date\":i, \"rows\":file_lines[i]} for i in file_lines])\n",
    "    top_10_days = top_10_days.sort_values(\"rows\", ascending = False)[:10]\n",
    "    top_10_days = list(top_10_days['date'])\n",
    "    \n",
    "    result_list = []\n",
    "    for i in top_10_days:\n",
    "        data_tmp = pd.read_json(f'data_q1/{i}', orient='records', lines=True)\n",
    "        data_tmp = data_tmp.groupby(\"user\").count().sort_values(\"id\", ascending = False)[:1]\n",
    "        user = data_tmp.index.values[0]\n",
    "        result_list.append((i, user))\n",
    "    \n",
    "    # delete all previous files generated\n",
    "    directory_path = 'data_q1'\n",
    "    file_list = os.listdir(directory_path)\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "\n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 149.06 MiB, increment: 10.73 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Los top 10 emojis más usados con su respectivo conteo. Debe incluir las siguientes funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    #En este caso haremos la lectura igual que en la primera pregunta pero extraeremos unicamente el campo content\n",
    "    file_data = open(file_path, 'r')\n",
    "    Lines = file_data.readlines()\n",
    "    data = []\n",
    "\n",
    "    for line in Lines:\n",
    "        json_value = json.loads(line)\n",
    "        data.append(json_value.get(\"content\"))\n",
    "\n",
    "    emoji_values = []\n",
    "    \n",
    "    for i in data:\n",
    "        emoji_values += [value.chars for value in emoji.analyze(i)]\n",
    "\n",
    "    #Vamos a crear un dataframe con los resultados\n",
    "    data = pd.DataFrame({\"emoji\":emoji_values})\n",
    "    data[\"counter\"] = 1\n",
    "    data = data.groupby('emoji').sum().sort_values(\"counter\", ascending = False).head(10)\n",
    "    emoji_list = [tuple(i) for i in data[[\"counter\"]].itertuples()]\n",
    "    file_data.close() #Liberamos memoria\n",
    "    return emoji_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 594.25 MiB, increment: 20.25 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit resultado_q2_time = q2_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.6 s ± 2.47 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit resultado_q2_time = q2_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 5049),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('🌾', 2182),\n",
       " ('🇮🇳', 2086),\n",
       " ('🤣', 1668),\n",
       " ('✊', 1651),\n",
       " ('❤️', 1382),\n",
       " ('🙏🏻', 1317),\n",
       " ('💚', 1040)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimir resultado\n",
    "resultado_q2_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Para evitar consumir la memoria en la lectura del archivo iremos leyendo linea a linea el archivo\n",
    "    # haremos una cuenta un agrupamiento previo e iremos almacenando en un archivo\n",
    "\n",
    "    # Lectura linea a linea\n",
    "    file1 = open(file_path,\"r\")\n",
    "    fwrite = open(\"aux_mem_q2/emoji_data\",\"a\")\n",
    "    file_read = open(\"aux_mem_q2/emoji_data\",\"r\")\n",
    "\n",
    "    for line in file1:\n",
    "        json_value = json.loads(line)\n",
    "        # Leeremos solo el valor del content donde estar los emojis\n",
    "        content = json_value.get(\"content\")\n",
    "        \n",
    "        #Extraemos emojis y los agrupamos\n",
    "        tmp_emoji_list = [value.chars for value in emoji.analyze(content)]\n",
    "        tmp_emoji_list = '\\n'.join(tmp_emoji_list)\n",
    "        \n",
    "        if tmp_emoji_list: #Emojis existen\n",
    "            fwrite.write(tmp_emoji_list+\"\\n\")\n",
    "\n",
    "    file1.close()\n",
    "    fwrite.close()\n",
    "        \n",
    "    # Ahora leeremos el archivo fila a fila y almacenaremos en un dictionario de datos sumando uno por cada ocurrencia\n",
    "    emoji_values = {}\n",
    "\n",
    "    for emoji_line in file_read:\n",
    "        if emoji_line.replace('\\n','') in emoji_values.keys():\n",
    "            emoji_values[emoji_line.replace('\\n','')] +=1 # Si existe se suma uno\n",
    "        else:\n",
    "            emoji_values[emoji_line.replace('\\n','')] = 0 # Si no existe lo crea\n",
    "    \n",
    "    #Lo hacemos dataframe para agrupar y sacar los maximos\n",
    "    emoji_values = pd.DataFrame({\"emoji\":list(emoji_values.keys()),\"conteo\":list(emoji_values.values())})\n",
    "    emoji_values = emoji_values.sort_values('conteo', ascending=False).head(10)\n",
    "\n",
    "    # #Lo volvemos listado de tuplas\n",
    "    emoji_values = [tuple(i) for i in emoji_values.set_index('emoji').itertuples()]\n",
    "\n",
    "    # Borrar el archivo generado\n",
    "    os.remove('aux_mem_q2/emoji_data')\n",
    "    file1.close()\n",
    "    \n",
    "    return emoji_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_625561/4261480298.py\", line 1, in <module>\n",
      "    get_ipython().run_line_magic('memit', 'x = q2_memory(file_path)')\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2432, in run_line_magic\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/memory_profiler.py\", line 1113, in memit\n",
      "    tmp = memory_usage((_func_exec, (stmt, self.shell.user_ns)),\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/memory_profiler.py\", line 379, in memory_usage\n",
      "    returned = f(*args, **kw)\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/memory_profiler.py\", line 889, in _func_exec\n",
      "    exec(stmt, ns)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/tmp/ipykernel_625561/541766779.py\", line 41, in q2_memory\n",
      "    emoji_values = [tuple(i) for i in emoji_values.set_index('emojis').itertuples()]\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/pandas/core/frame.py\", line 6012, in set_index\n",
      "    raise KeyError(f\"None of {missing} are in the columns\")\n",
      "KeyError: \"None of ['emojis'] are in the columns\"\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1155, in get_records\n",
      "    FrameInfo(\n",
      "  File \"/home/diego/.venv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 780, in __init__\n",
      "    ix = inspect.getsourcelines(frame)\n",
      "  File \"/home/diego/.pyenv/versions/3.9.12/lib/python3.9/inspect.py\", line 1006, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/home/diego/.pyenv/versions/3.9.12/lib/python3.9/inspect.py\", line 835, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "%memit x = q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>conteo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>🙏</td>\n",
       "      <td>5048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>😂</td>\n",
       "      <td>3071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🚜</td>\n",
       "      <td>2971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>🌾</td>\n",
       "      <td>2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>🇮🇳</td>\n",
       "      <td>2085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>🤣</td>\n",
       "      <td>1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>✊</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>❤️</td>\n",
       "      <td>1381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>🙏🏻</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>💚</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emoji  conteo\n",
       "48     🙏    5048\n",
       "29     😂    3071\n",
       "0      🚜    2971\n",
       "1      🌾    2181\n",
       "6     🇮🇳    2085\n",
       "15     🤣    1667\n",
       "36     ✊    1650\n",
       "56    ❤️    1381\n",
       "11    🙏🏻    1316\n",
       "32     💚    1039"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@)\n",
    "que registra cada uno de ellos. Debe incluir las siguientes funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    return 0"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "445f001600bf7eb0ddc22245e91c6123825f79238ec2a014331a6132a9c2d200"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
